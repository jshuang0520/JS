{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline_example\n",
    "\n",
    "https://www.kaggle.com/ml100marathon/baseline-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_id</td>\n",
       "      <td>用戶 ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchant_id</td>\n",
       "      <td>商家 ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coupon_id</td>\n",
       "      <td>優惠券 ID (null 代表無優惠券消費)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discount_rate</td>\n",
       "      <td>優惠券折價：[0,1] 代表折扣率；x:y 代表滿 x 減 y 元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Distance</td>\n",
       "      <td>用戶經常活動地點離商家最近距離 (x * 500 公尺), 0 表示低於 500 公尺, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Date_received</td>\n",
       "      <td>優惠券取得時間</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Date</td>\n",
       "      <td>購買商品時間 (如果 Date is null &amp; Coupon_id is not nul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column                                        Description\n",
       "0        User_id                                              用戶 ID\n",
       "1    Merchant_id                                              商家 ID\n",
       "2      Coupon_id                             優惠券 ID (null 代表無優惠券消費)\n",
       "3  Discount_rate                  優惠券折價：[0,1] 代表折扣率；x:y 代表滿 x 減 y 元\n",
       "4       Distance  用戶經常活動地點離商家最近距離 (x * 500 公尺), 0 表示低於 500 公尺, 1...\n",
       "5  Date_received                                            優惠券取得時間\n",
       "6           Date  購買商品時間 (如果 Date is null & Coupon_id is not nul..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set data_path\n",
    "data_path = '/Users/johnsonhuang/py_ds/ML_100/2nd-ML100Days/homework/Day_051To053_HW/'\n",
    "column_description = pd.read_csv(os.path.join(data_path, 'column_description.csv'), encoding = \"big5\") # 因為預設不是utf8，如果不設這參數會unidecodeerror\n",
    "column_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欄位說明 (與 column_description.csv 相同) \n",
    "\n",
    "<font color = \"red\">User_id</font>：用戶 ID \n",
    "\n",
    "<font color = \"red\">Merchant_id</font>：商家 ID \n",
    "\n",
    "<font color = \"red\">Coupon_id</font>：優惠券 ID (null 代表無優惠券消費) \n",
    "\n",
    "<font color = \"red\">Discount_rate</font>：優惠券折價</font>：[0,1] 代表折扣率；x:y 代表滿 x 減 y 元 \n",
    "\n",
    "<font color = \"red\">Distance</font>：用戶經常活動地點離商家最近距離 (x * 500 公尺), 0 表示低於 500 公尺, 10 表示大於 5 公里。 \n",
    "\n",
    "<font color = \"red\">Date_received</font>：優惠券取得時間。 \n",
    "\n",
    "<font color = \"red\">Date</font>：購買商品時間 (如果 Date is null & Coupon_id is not null, 則該紀錄為有優惠券但未使用; 若為 Date is not null & Coupon_id is null, 則為普通消費日期; 若 Date is not null & Coupon_id is not null, 則表示優惠券消費日期)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set data_path\n",
    "data_path = '/Users/johnsonhuang/py_ds/ML_100/2nd-ML100Days/homework/Day_051To053_HW/'\n",
    "train = pd.read_csv(os.path.join(data_path, 'train_offline.csv'))\n",
    "test = pd.read_csv(os.path.join(data_path, 'test_offline.csv'))\n",
    "test = test[~test.Coupon_id.isna()]\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    710665\n",
       "-1    413773\n",
       " 1     36304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(row):\n",
    "    # buy without coupon\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    # buy with coupon within (include) 15 days ==> 1 ; buy with coupon but out of 15 days ==> 0\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "train[\"label\"] = train.apply(label, axis=1)\n",
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "# Generate features - weekday acquired coupon\n",
    "def getWeekday(row):\n",
    "    if (np.isnan(row)) or (row==-1):\n",
    "        return row\n",
    "    else:\n",
    "        return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n",
    "\n",
    "train['weekday'] = train['Date_received'].apply(getWeekday)\n",
    "test['weekday'] = test['Date_received'].apply(getWeekday)\n",
    "\n",
    "# weekday_type (weekend = 1)\n",
    "train['weekday_type'] = train['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to trainset\n",
    "test['weekday_type'] = test['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to testset\n",
    "\n",
    "# weekday get_dummies\n",
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(train['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "train[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(test['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "test[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>discount_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "\n",
       "         Date  label  weekday  weekday_type      ...        weekday_2  \\\n",
       "0  20160217.0     -1      NaN             0      ...                0   \n",
       "1         NaN      0      3.0             0      ...                0   \n",
       "2         NaN      0      6.0             0      ...                0   \n",
       "3         NaN      0      5.0             0      ...                0   \n",
       "4         NaN      0      5.0             0      ...                0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  weekday_7  discount_rate  \\\n",
       "0          0          0          0          0          0            NaN   \n",
       "1          1          0          0          0          0           0.95   \n",
       "2          0          0          0          1          0           0.95   \n",
       "3          0          0          1          0          0           0.90   \n",
       "4          0          0          1          0          0           0.90   \n",
       "\n",
       "   discount_man  discount_jian  discount_type  \n",
       "0             0              0              0  \n",
       "1            20              1              1  \n",
       "2            20              1              1  \n",
       "3           200             20              1  \n",
       "4           200             20              1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features - coupon discount and distance\n",
    "\n",
    "\"\"\"\n",
    "Discount_rate\n",
    "ex. 20:1, 10:5, NaN\n",
    "\"\"\"\n",
    "\n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'null':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    return df\n",
    "\n",
    "train = processData(train)\n",
    "test = processData(test)\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_id               0\n",
       "Merchant_id           0\n",
       "Coupon_id        413773\n",
       "Discount_rate    413773\n",
       "Distance              0\n",
       "Date_received    413773\n",
       "Date             704033\n",
       "label                 0\n",
       "weekday          413773\n",
       "weekday_type          0\n",
       "weekday_1             0\n",
       "weekday_2             0\n",
       "weekday_3             0\n",
       "weekday_4             0\n",
       "weekday_5             0\n",
       "weekday_6             0\n",
       "weekday_7             0\n",
       "discount_rate    413773\n",
       "discount_man          0\n",
       "discount_jian         0\n",
       "discount_type         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 去除掉 \"buy without coupon ==> -1\"\n",
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "train = train[~train.label < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\n"
     ]
    }
   ],
   "source": [
    "# 在取得優惠卷15天以內或以外才消費的消費者，每人not unique商家數（購物趟數）\n",
    "\"\"\"\n",
    "g = df_preprocess_eventall.groupby('Member')\n",
    "g.apply(lambda x: x[x['Status'] == 'WON']['Member_Win_Loss'].sum())\n",
    "df1[\"overall_WON_amount\"] = g.apply(lambda x: x[x['Status'] == 'WON']['Member_Win_Loss'].sum()).values   ＃用.values\n",
    "\n",
    "sum(if(MEMBERWinLoss>0,MEMBERWinLoss,0))/(count(case Betstatus when 'WON' then 1 end)) as AvgWin,\n",
    "\"\"\"\n",
    "\n",
    "# train_merchantNumPerUserIn15D = train.groupby('User_id').apply(lambda x: x[x['label'] == 1]['Merchant_id'].count()).fillna(value=0).values   #用.values\n",
    "# train_merchantNumPerUserMore15 = train.groupby('User_id').apply(lambda x: x[x['label'] == 0]['Merchant_id'].count()).fillna(value=0).values   #用.values\n",
    "\n",
    "\n",
    "# train_merchantNumPerUserIn15D = (train.groupby('User_id').apply(lambda x: x[x['label'] == 1]['Merchant_id'].count())).to_frame().rename(columns = {0 : \"merchantNumPerUserIn15D\"}).reset_index()\n",
    "# train_merchantNumPerUserMore15D = (train.groupby('User_id').apply(lambda x: x[x['label'] == 0]['Merchant_id'].count())).to_frame().rename(columns = {0 : \"merchantNumPerUserMore15D\"}).reset_index()\n",
    "# train = pd.merge(train, train_merchantNumPerUserIn15D, how = \"left\", on = [\"User_id\"])\n",
    "# train = pd.merge(train, train_merchantNumPerUserMore15D, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "print(\"test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在取得優惠卷15天以內或以外才消費的消費者，每人 平均購物距離\n",
    "\n",
    "# train[\"distPerUser<=15\"] = train.groupby('User_id').apply(lambda x: x[x['label'] == 1]['Distance'].mean()).fillna(value=0).values   #用.values\n",
    "# train[\"distPerUser>15\"] = train.groupby('User_id').apply(lambda x: x[x['label'] == 0]['Distance'].mean()).fillna(value=0).values   #用.values\n",
    "\n",
    "\n",
    "# train_distPerUserIn15D = (train.groupby('User_id').apply(lambda x: x[x['label'] == 1]['Distance'].mean())).to_frame().rename(columns = {0 : \"distPerUserIn15D\"}).reset_index()\n",
    "# train_distPerUserMore15D = (train.groupby('User_id').apply(lambda x: x[x['label'] == 0]['Distance'].mean())).to_frame().rename(columns = {0 : \"distPerUserMore15D\"}).reset_index()\n",
    "# train = pd.merge(train, train_distPerUserIn15D, how = \"left\", on = [\"User_id\"])\n",
    "# train = pd.merge(train, train_distPerUserMore15D, how = \"left\", on = [\"User_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- train ---\n",
    "\n",
    "# 每人not unique商家數（購物趟數）\n",
    "train_merchantNumPerUser = (train.groupby('User_id')['Merchant_id'].count()).to_frame().rename(columns = {\"Merchant_id\" : \"merchantNumPerUser\"}).reset_index()\n",
    "train = pd.merge(train, train_merchantNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# 每人 平均購物距離\n",
    "train_distPerUser = (train.groupby('User_id')['Distance'].mean()).to_frame().rename(columns = {\"Distance\" : \"distPerUser\"}).reset_index()\n",
    "train = pd.merge(train, train_distPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# --- test ---\n",
    "\n",
    "# 每人not unique商家數（購物趟數）\n",
    "test_merchantNumPerUser = (test.groupby('User_id')['Merchant_id'].count()).to_frame().rename(columns = {\"Merchant_id\" : \"merchantNumPerUser\"}).reset_index()\n",
    "test = pd.merge(test, test_merchantNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# 每人 平均購物距離\n",
    "test_distPerUser = (test.groupby('User_id')['Distance'].mean()).to_frame().rename(columns = {\"Distance\" : \"distPerUser\"}).reset_index()\n",
    "test = pd.merge(test, test_distPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- train ---\n",
    "\n",
    "# 每人優惠卷數\n",
    "train_couponNumPerUser = (train.groupby('User_id')['Coupon_id'].count()).to_frame().rename(columns = {\"Coupon_id\" : \"couponNumPerUser\"}).reset_index()\n",
    "train = pd.merge(train, train_couponNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# 折扣率低於八折的優惠卷數量 (我覺得比較有優惠到的叫做八折啦)\n",
    "train_goodDiscountCouNumPerUser = (train.groupby('User_id').apply(lambda x: x[x['discount_rate'] <= 0.8]['Coupon_id'].count())).to_frame().rename(columns = {0 : \"goodDiscountCouNumPerUser\"}).reset_index()\n",
    "train = pd.merge(train, train_goodDiscountCouNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# --- test ---\n",
    "\n",
    "# 每人優惠卷數\n",
    "test_couponNumPerUser = (test.groupby('User_id')['Coupon_id'].count()).to_frame().rename(columns = {\"Coupon_id\" : \"couponNumPerUser\"}).reset_index()\n",
    "test = pd.merge(test, test_couponNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n",
    "# 折扣率低於八折的優惠卷數量 (我覺得比較有優惠到的叫做八折啦)\n",
    "test_goodDiscountCouNumPerUser = (test.groupby('User_id').apply(lambda x: x[x['discount_rate'] <= 0.8]['Coupon_id'].count())).to_frame().rename(columns = {0 : \"goodDiscountCouNumPerUser\"}).reset_index()\n",
    "test = pd.merge(test, test_goodDiscountCouNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\n"
     ]
    }
   ],
   "source": [
    "# # 每個人 取得優惠券 卻沒消費的次數\n",
    "# def wastedCouponNumPerUser(df) :\n",
    "#     wastedCouponNumPerUser = (df.groupby('User_id').apply(lambda x: x[np.isnan(x['Date'])==True]['Coupon_id'].count())).to_frame().rename(columns = {\"Coupon_id\" : \"wastedCouponNumPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, wastedCouponNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "#     return df\n",
    "\n",
    "# wastedCouponNumPerUser(train)\n",
    "# wastedCouponNumPerUser(test)\n",
    "\n",
    "print(\"test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_id                           0\n",
       "Merchant_id                       0\n",
       "Coupon_id                         0\n",
       "Discount_rate                     0\n",
       "Distance                          0\n",
       "Date_received                     0\n",
       "Date                         704033\n",
       "label                             0\n",
       "weekday                           0\n",
       "weekday_type                      0\n",
       "weekday_1                         0\n",
       "weekday_2                         0\n",
       "weekday_3                         0\n",
       "weekday_4                         0\n",
       "weekday_5                         0\n",
       "weekday_6                         0\n",
       "weekday_7                         0\n",
       "discount_rate                     0\n",
       "discount_man                      0\n",
       "discount_jian                     0\n",
       "discount_type                     0\n",
       "merchantNumPerUser                0\n",
       "distPerUser                       0\n",
       "couponNumPerUser                  0\n",
       "goodDiscountCouNumPerUser         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 拿到優惠券低於八折的 每人 活躍地點距離商家的平均距離\n",
    "def goodDiscountrateAvgDistPerUser(df) :\n",
    "    goodDiscountrateAvgDistPerUser = (df.groupby('User_id').apply(lambda x: x[x['discount_rate'] <= 0.8]['Distance'].mean())).to_frame().rename(columns = {0 : \"goodDiscountrateAvgDistPerUser\"}).reset_index()\n",
    "    df = pd.merge(df, goodDiscountrateAvgDistPerUser, how = \"left\", on = [\"User_id\"])\n",
    "    return df\n",
    "\n",
    "train = goodDiscountrateAvgDistPerUser(train)\n",
    "test = goodDiscountrateAvgDistPerUser(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test[\"Distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_7</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>merchantNumPerUser</th>\n",
       "      <th>distPerUser</th>\n",
       "      <th>couponNumPerUser</th>\n",
       "      <th>goodDiscountCouNumPerUser</th>\n",
       "      <th>goodDiscountrateAvgDistPerUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>106443</td>\n",
       "      <td>450</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>49.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2621792</td>\n",
       "      <td>4433</td>\n",
       "      <td>190.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>983640</td>\n",
       "      <td>6134</td>\n",
       "      <td>767.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4465344</td>\n",
       "      <td>8386</td>\n",
       "      <td>9847.0</td>\n",
       "      <td>200:50</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "5     73611         2099    12034.0        100:10      99.0     20160207.0   \n",
       "25   106443          450     3732.0          30:5      99.0     20160429.0   \n",
       "28  2621792         4433      190.0        200:20      99.0     20160131.0   \n",
       "54   983640         6134      767.0        200:20      99.0     20160124.0   \n",
       "68  4465344         8386     9847.0        200:50      99.0     20160126.0   \n",
       "\n",
       "    Date  label  weekday  weekday_type               ...                \\\n",
       "5    NaN      0      7.0             0               ...                 \n",
       "25   NaN      0      5.0             0               ...                 \n",
       "28   NaN      0      7.0             0               ...                 \n",
       "54   NaN      0      7.0             0               ...                 \n",
       "68   NaN      0      2.0             0               ...                 \n",
       "\n",
       "    weekday_7  discount_rate  discount_man  discount_jian  discount_type  \\\n",
       "5           1       0.900000           100             10              1   \n",
       "25          0       0.833333            30              5              1   \n",
       "28          1       0.900000           200             20              1   \n",
       "54          1       0.900000           200             20              1   \n",
       "68          0       0.750000           200             50              1   \n",
       "\n",
       "    merchantNumPerUser  distPerUser  couponNumPerUser  \\\n",
       "5                    1         99.0                 1   \n",
       "25                   2         49.5                 2   \n",
       "28                   1         99.0                 1   \n",
       "54                   1         99.0                 1   \n",
       "68                   7         99.0                 7   \n",
       "\n",
       "    goodDiscountCouNumPerUser  goodDiscountrateAvgDistPerUser  \n",
       "5                           0                             NaN  \n",
       "25                          0                             NaN  \n",
       "28                          0                             NaN  \n",
       "54                          0                             NaN  \n",
       "68                          1                            99.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train[\"Distance\"]==99,:].iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na of goodDiscountrateAvgDistPerUser 為 99 (max值)\n",
    "train[['goodDiscountrateAvgDistPerUser']] = train[['goodDiscountrateAvgDistPerUser']].fillna(value=99)\n",
    "test[['goodDiscountrateAvgDistPerUser']] = test[['goodDiscountrateAvgDistPerUser']].fillna(value=99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每位 user 在各 merchant 拿到的 coupon 數\n",
    "def couponNumInEachMerPerUser(df) :\n",
    "    couponNumInEachMerPerUser = (df.groupby(['User_id', 'Merchant_id'])['Coupon_id'].count()).to_frame().rename(columns = {\"Coupon_id\" : \"couponNumInEachMerPerUser\"}).reset_index()\n",
    "    df = pd.merge(df, couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    return df\n",
    "\n",
    "train = couponNumInEachMerPerUser(train)\n",
    "test = couponNumInEachMerPerUser(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每位 user 有的 unique merchant 數\n",
    "def NUniqueMerNumPerUser(df) :\n",
    "    NUniqueMerNumPerUser = (df.groupby(['User_id'])['Merchant_id'].nunique()).to_frame().rename(columns = {\"Merchant_id\" : \"NUniqueMerNumPerUser\"}).reset_index()\n",
    "    df = pd.merge(df, NUniqueMerNumPerUser, how = \"left\", on = [\"User_id\"])\n",
    "    return df\n",
    "\n",
    "train = NUniqueMerNumPerUser(train)\n",
    "test = NUniqueMerNumPerUser(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 看提交結果感覺是沒什麼幫助的特徵\n",
    "\n",
    "# # 每位 user 在各 merchant 在 星期一到日 拿到的 coupon 數\n",
    "# def day_i_couponNumInEachMerPerUser(df) :\n",
    "# #     for i in range(1, 8) :\n",
    "# #         exec(f'day_{i}_couponNumInEachMerPerUser = (df.groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_{i}\"] == 1][\"Coupon_id\"].count())).to_frame().reset_index()')\n",
    "# #         # rename column 用原本dict的方式那個大括號{}會跟exec的{}打架，所以改成這樣\n",
    "# #         exec(f'day_{i}_couponNumInEachMerPerUser.columns = [\"User_id\", \"Merchant_id\", \"day_{i}_couponNumInEachMerPerUser\"]')\n",
    "# #         exec(f'df = pd.merge(df, day_{i}_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])')\n",
    "    \n",
    "#     colFor_couponNumInEachMerPerUser = [\"User_id\", \"Merchant_id\", \"Coupon_id\", \n",
    "#                                         \"weekday_1\", \"weekday_2\", \"weekday_3\",\n",
    "#                                         \"weekday_4\", \"weekday_5\", \"weekday_6\", \"weekday_7\"]\n",
    "    \n",
    "#     day_1_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_1\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_1_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_1_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_2_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_2\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_2_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_2_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_3_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_3\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_3_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_3_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_4_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_4\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_4_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_4_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_5_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_5\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_5_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_5_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_6_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_6\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_6_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_6_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "    \n",
    "#     day_7_couponNumInEachMerPerUser = (df[colFor_couponNumInEachMerPerUser].groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_7\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_7_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_7_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "# train = day_i_couponNumInEachMerPerUser(train)\n",
    "# test = day_i_couponNumInEachMerPerUser(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 每位 user 在各 merchant 在 星期一到日 拿到的 coupon 數\n",
    "# def day_2_couponNumInEachMerPerUser(df) :\n",
    "    \n",
    "#     day_2_couponNumInEachMerPerUser = (df.groupby([\"User_id\", \"Merchant_id\"]).apply(lambda x: x[x[\"weekday_2\"] == 1][\"Coupon_id\"].count())).to_frame().rename(columns = {0 : \"day_2_couponNumInEachMerPerUser\"}).reset_index()\n",
    "#     df = pd.merge(df, day_2_couponNumInEachMerPerUser, how = \"left\", on = [\"User_id\", \"Merchant_id\"])\n",
    "#     return df\n",
    "\n",
    "# # train = day_i_couponNumInEachMerPerUser(train)\n",
    "# # test = day_i_couponNumInEachMerPerUser(test)\n",
    "\n",
    "# day_2_couponNumInEachMerPerUser(test.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df['DiscountRatio'] = total_df.Discount_rate.map( lambda x: (1 - float(x.split(':')[1])/float(x.split(':')[0])) if(':' in x) else float(x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " << na_check(train) >>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>94.25197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing Ratio\n",
       "Date       94.25197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " << na_check(test) >>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n << na_check(train) >>\")\n",
    "display(na_check(train))\n",
    "\n",
    "print(\"\\n << na_check(test) >>\")\n",
    "display(na_check(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeature(dataset3):\n",
    "    # this_month_user_receive_all_coupon_count\n",
    "    t = dataset3[['User_id']]\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "\n",
    "    # this_month_user_receive_same_coupon_count\n",
    "    t1 = dataset3[['User_id','Coupon_id']]\n",
    "    t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "    t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "    \n",
    "    t2 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t2.Date_received = t2.Date_received.astype('str')\n",
    "    t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    t2['receive_number'] = t2.Date_received.apply(lambda s:len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number>1]\n",
    "    t2['max_Date_received'] = t2.Date_received.apply(lambda s:max([float(d) for d in s.split(':')]))\n",
    "    t2['min_Date_received'] = t2.Date_received.apply(lambda s:min([float(d) for d in s.split(':')]))\n",
    "    t2 = t2[['User_id','Coupon_id','max_Date_received','min_Date_received']]\n",
    "\n",
    "    # this_month_user_receive_same_coupon_lastone, this_month_user_receive_same_coupon_firstone\n",
    "    t3 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t3 = pd.merge(t3,t2,on=['User_id','Coupon_id'],how='left')\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] = t3.max_Date_received - t3.Date_received\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.Date_received - t3.min_Date_received\n",
    "    \n",
    "    def is_firstlastone(x):\n",
    "        if x==0:\n",
    "            return 1\n",
    "        elif x>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1 #those only receive once\n",
    "\n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "    t3 = t3[['User_id','Coupon_id','Date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "    t4 = dataset3[['User_id','Date_received']]\n",
    "    t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "    t5 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "    t6 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t6.Date_received = t6.Date_received.astype('str')\n",
    "    t6 = t6.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    t6.rename(columns={'Date_received':'dates'},inplace=True)\n",
    "\n",
    "    def get_day_gap_before(s):\n",
    "        if str(s)==\"nan\":\n",
    "            return -1\n",
    "        Date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "    def get_day_gap_after(s):\n",
    "        if str(s)==\"nan\":\n",
    "            return -1\n",
    "        Date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "\n",
    "    t7 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t7 = pd.merge(t7,t6,on=['User_id','Coupon_id'],how='left')\n",
    "    t7['Date_received_date'] = t7.Date_received.astype('str') + '-' + t7.dates\n",
    "    t7['day_gap_before'] = t7.Date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.Date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[['User_id','Coupon_id','Date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "    other_feature3 = pd.merge(t1,t,on='User_id')\n",
    "    other_feature3 = pd.merge(other_feature3,t3,on=['User_id','Coupon_id'])\n",
    "    other_feature3 = pd.merge(other_feature3,t4,on=['User_id','Date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3,t5,on=['User_id','Coupon_id','Date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3,t7,on=['User_id','Coupon_id','Date_received'])\n",
    "    #other_feature3.to_csv('data/other_feature3.csv',index=None)\n",
    "    \n",
    "    return other_feature3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train2.head() \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>...</th>\n",
       "      <th>day_6_couponNumInEachMerPerUser</th>\n",
       "      <th>day_7_couponNumInEachMerPerUser</th>\n",
       "      <th>this_month_user_receive_same_coupon_count</th>\n",
       "      <th>this_month_user_receive_all_coupon_count</th>\n",
       "      <th>this_month_user_receive_same_coupon_lastone</th>\n",
       "      <th>this_month_user_receive_same_coupon_firstone</th>\n",
       "      <th>this_day_user_receive_all_coupon_count</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>day_gap_before</th>\n",
       "      <th>day_gap_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "1  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "2  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "3  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "4  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "\n",
       "   Date  label  weekday  weekday_type      ...        \\\n",
       "0   NaN      0      3.0             0      ...         \n",
       "1   NaN      0      6.0             0      ...         \n",
       "2   NaN      0      5.0             0      ...         \n",
       "3   NaN      0      5.0             0      ...         \n",
       "4   NaN      0      5.0             0      ...         \n",
       "\n",
       "   day_6_couponNumInEachMerPerUser  day_7_couponNumInEachMerPerUser  \\\n",
       "0                                1                                0   \n",
       "1                                1                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   this_month_user_receive_same_coupon_count  \\\n",
       "0                                          1   \n",
       "1                                          1   \n",
       "2                                          1   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "\n",
       "   this_month_user_receive_all_coupon_count  \\\n",
       "0                                         2   \n",
       "1                                         2   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   this_month_user_receive_same_coupon_lastone  \\\n",
       "0                                           -1   \n",
       "1                                           -1   \n",
       "2                                           -1   \n",
       "3                                           -1   \n",
       "4                                           -1   \n",
       "\n",
       "   this_month_user_receive_same_coupon_firstone  \\\n",
       "0                                            -1   \n",
       "1                                            -1   \n",
       "2                                            -1   \n",
       "3                                            -1   \n",
       "4                                            -1   \n",
       "\n",
       "   this_day_user_receive_all_coupon_count  \\\n",
       "0                                       1   \n",
       "1                                       1   \n",
       "2                                       1   \n",
       "3                                       1   \n",
       "4                                       1   \n",
       "\n",
       "   this_day_user_receive_same_coupon_count  day_gap_before  day_gap_after  \n",
       "0                                        1              -1             -1  \n",
       "1                                        1              -1             -1  \n",
       "2                                        1              -1             -1  \n",
       "3                                        1              -1             -1  \n",
       "4                                        1              -1             -1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2.head() \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>...</th>\n",
       "      <th>day_6_couponNumInEachMerPerUser</th>\n",
       "      <th>day_7_couponNumInEachMerPerUser</th>\n",
       "      <th>this_month_user_receive_same_coupon_count</th>\n",
       "      <th>this_month_user_receive_all_coupon_count</th>\n",
       "      <th>this_month_user_receive_same_coupon_lastone</th>\n",
       "      <th>this_month_user_receive_same_coupon_firstone</th>\n",
       "      <th>this_day_user_receive_all_coupon_count</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>day_gap_before</th>\n",
       "      <th>day_gap_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160516.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2029232</td>\n",
       "      <td>450</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160530.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>6459</td>\n",
       "      <td>12737.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160519.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160516.0   \n",
       "3  2029232          450     1532.0          30:5       0.0     20160530.0   \n",
       "4  2029232         6459    12737.0          20:1       0.0     20160519.0   \n",
       "\n",
       "   weekday  weekday_type  weekday_1  weekday_2      ...        \\\n",
       "0        6             0          0          0      ...         \n",
       "1        1             0          1          0      ...         \n",
       "2        1             0          1          0      ...         \n",
       "3        1             0          1          0      ...         \n",
       "4        4             0          0          0      ...         \n",
       "\n",
       "   day_6_couponNumInEachMerPerUser  day_7_couponNumInEachMerPerUser  \\\n",
       "0                                1                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   this_month_user_receive_same_coupon_count  \\\n",
       "0                                          1   \n",
       "1                                          2   \n",
       "2                                          2   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "\n",
       "   this_month_user_receive_all_coupon_count  \\\n",
       "0                                         3   \n",
       "1                                         3   \n",
       "2                                         3   \n",
       "3                                         2   \n",
       "4                                         2   \n",
       "\n",
       "   this_month_user_receive_same_coupon_lastone  \\\n",
       "0                                           -1   \n",
       "1                                            1   \n",
       "2                                            0   \n",
       "3                                           -1   \n",
       "4                                           -1   \n",
       "\n",
       "   this_month_user_receive_same_coupon_firstone  \\\n",
       "0                                            -1   \n",
       "1                                             0   \n",
       "2                                             1   \n",
       "3                                            -1   \n",
       "4                                            -1   \n",
       "\n",
       "   this_day_user_receive_all_coupon_count  \\\n",
       "0                                       1   \n",
       "1                                       1   \n",
       "2                                       1   \n",
       "3                                       1   \n",
       "4                                       1   \n",
       "\n",
       "   this_day_user_receive_same_coupon_count  day_gap_before  day_gap_after  \n",
       "0                                        1              -1             -1  \n",
       "1                                        1              28             -1  \n",
       "2                                        1              -1             28  \n",
       "3                                        1              -1             -1  \n",
       "4                                        1              -1             -1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_moreFeatures = extractFeature(train)\n",
    "test_moreFeatures = extractFeature(test)\n",
    "\n",
    "# 將額外的feature併回去\n",
    "train2 = pd.merge(train, train_moreFeatures, how = 'left', on = ['User_id', 'Coupon_id', 'Date_received'])\n",
    "print(\"train2.head()\", \"\\n\")\n",
    "display(train2.head())\n",
    "\n",
    "test2 = pd.merge(test, test_moreFeatures, how = 'left', on = ['User_id', 'Coupon_id', 'Date_received'])\n",
    "print(\"test2.head()\", \"\\n\")\n",
    "display(test2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates 最後要預測的筆數才對，才能提交預測檔\n",
    "\n",
    "train2 = train2.drop_duplicates().reset_index(drop = True)\n",
    "test2 = test2.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# 因為之後的test2要取特徵的那些col而已，這邊先複製一份，作為提交檔取User_id, Coupon_id等等所用\n",
    "train2_cp = train2.copy()\n",
    "test2_cp = test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\n"
     ]
    }
   ],
   "source": [
    "## user - merchant  Feature\n",
    "\n",
    "# def extract_user_merchant_Feature(feature3):\n",
    "#     \"\"\"\n",
    "#     4.user_merchant:\n",
    "#           times_user_buy_merchant_before. \n",
    "#     \"\"\"\n",
    "#     #for dataset3\n",
    "#     all_user_merchant = feature3[['User_id','Merchant_id']]\n",
    "#     all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t = feature3[['User_id','Merchant_id','Date']]\n",
    "#     t = t[t.Date!='null'][['User_id','Merchant_id']]\n",
    "#     t['user_merchant_buy_total'] = 1\n",
    "#     t = t.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t1 = feature3[['User_id','Merchant_id','Coupon_id']]\n",
    "#     t1 = t1[t1.Coupon_id!='null'][['User_id','Merchant_id']]\n",
    "#     t1['user_merchant_received'] = 1\n",
    "#     t1 = t1.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t1.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t2 = feature3[['User_id','Merchant_id','Date','Date_received']]\n",
    "#     t2 = t2[(t2.Date!='null')&(t2.Date_received!='null')][['User_id','Merchant_id']]\n",
    "#     t2['user_merchant_buy_use_coupon'] = 1\n",
    "#     t2 = t2.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t2.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t3 = feature3[['User_id','Merchant_id']]\n",
    "#     t3['user_merchant_any'] = 1\n",
    "#     t3 = t3.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t3.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t4 = feature3[['User_id','Merchant_id','Date','Coupon_id']]\n",
    "#     t4 = t4[(t4.Date!='null')&(t4.Coupon_id=='null')][['User_id','Merchant_id']]\n",
    "#     t4['user_merchant_buy_common'] = 1\n",
    "#     t4 = t4.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t4.drop_duplicates(inplace=True)\n",
    "\n",
    "#     user_merchant3 = pd.merge(all_user_merchant,t,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant3 = pd.merge(user_merchant3,t1,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant3 = pd.merge(user_merchant3,t2,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant3 = pd.merge(user_merchant3,t3,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant3 = pd.merge(user_merchant3,t4,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "#     user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "#     user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "#     user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "#     user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "#     user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    \n",
    "#     return user_merchant3\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# train_user_merchant_Feature = extract_user_merchant_Feature(train)\n",
    "# test_user_merchant_Feature = extract_user_merchant_Feature(test)\n",
    "\n",
    "# # 將額外的feature併回去\n",
    "# train3 = pd.merge(train2, train_user_merchant_Feature, how = 'left', on = ['User_id', 'Merchant_id'])\n",
    "# print(\"train3.head()\", \"\\n\")\n",
    "# display(train3.head())\n",
    "\n",
    "# test3 = pd.merge(test2, test_user_merchant_Feature, how = 'left', on = ['User_id', 'Merchant_id'])\n",
    "# print(\"test3.head()\", \"\\n\")\n",
    "# display(test3.head())\n",
    "\n",
    "\n",
    "\n",
    "# # drop duplicates 最後要預測的筆數才對，才能提交預測檔\n",
    "\n",
    "# train3 = train3.drop_duplicates().reset_index(drop = True)\n",
    "# test3 = test3.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# # 因為之後的test3要取特徵的那些col而已，這邊先複製一份，作為提交檔取User_id, Coupon_id等等所用\n",
    "# train3_cp = train3.copy()\n",
    "# test3_cp = test3.copy()\n",
    "\n",
    "\n",
    "\n",
    "print(\"test 沒有 Date(消費日期) 這個欄位，就無法衍生出label這個欄位，所以不能照這個想法做\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'Date', 'label', 'weekday', 'weekday_type',\n",
       "       'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5',\n",
       "       'weekday_6', 'weekday_7', 'discount_rate', 'discount_man',\n",
       "       'discount_jian', 'discount_type', 'merchantNumPerUser', 'distPerUser',\n",
       "       'couponNumPerUser', 'goodDiscountCouNumPerUser',\n",
       "       'goodDiscountrateAvgDistPerUser', 'couponNumInEachMerPerUser',\n",
       "       'NUniqueMerNumPerUser', 'day_1_couponNumInEachMerPerUser',\n",
       "       'day_2_couponNumInEachMerPerUser', 'day_3_couponNumInEachMerPerUser',\n",
       "       'day_4_couponNumInEachMerPerUser', 'day_5_couponNumInEachMerPerUser',\n",
       "       'day_6_couponNumInEachMerPerUser', 'day_7_couponNumInEachMerPerUser'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'Date', 'label', 'weekday', 'weekday_type',\n",
       "       'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5',\n",
       "       'weekday_6', 'weekday_7', 'discount_rate', 'discount_man',\n",
       "       'discount_jian', 'discount_type', 'merchantNumPerUser', 'distPerUser',\n",
       "       'couponNumPerUser', 'goodDiscountCouNumPerUser',\n",
       "       'goodDiscountrateAvgDistPerUser', 'couponNumInEachMerPerUser',\n",
       "       'NUniqueMerNumPerUser', 'day_1_couponNumInEachMerPerUser',\n",
       "       'day_2_couponNumInEachMerPerUser', 'day_3_couponNumInEachMerPerUser',\n",
       "       'day_4_couponNumInEachMerPerUser', 'day_5_couponNumInEachMerPerUser',\n",
       "       'day_6_couponNumInEachMerPerUser', 'day_7_couponNumInEachMerPerUser',\n",
       "       'this_month_user_receive_same_coupon_count',\n",
       "       'this_month_user_receive_all_coupon_count',\n",
       "       'this_month_user_receive_same_coupon_lastone',\n",
       "       'this_month_user_receive_same_coupon_firstone',\n",
       "       'this_day_user_receive_all_coupon_count',\n",
       "       'this_day_user_receive_same_coupon_count', 'day_gap_before',\n",
       "       'day_gap_after'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>this_month_user_receive_same_coupon_count</th>\n",
       "      <th>this_month_user_receive_all_coupon_count</th>\n",
       "      <th>this_month_user_receive_same_coupon_lastone</th>\n",
       "      <th>this_month_user_receive_same_coupon_firstone</th>\n",
       "      <th>this_day_user_receive_all_coupon_count</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>day_gap_before</th>\n",
       "      <th>day_gap_after</th>\n",
       "      <th>couponNumInEachMerPerUser</th>\n",
       "      <th>NUniqueMerNumPerUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4061024</td>\n",
       "      <td>2709</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4061024</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4061024</td>\n",
       "      <td>7555</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4061024</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7073472</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id  \\\n",
       "0   1439408         2632     8591.0   \n",
       "1   1439408         2632     1078.0   \n",
       "2   1832624         3381     7610.0   \n",
       "3   2029232         3381    11951.0   \n",
       "4   2223968         3381     9776.0   \n",
       "5     73611         2099    12034.0   \n",
       "6    163606         1569     5054.0   \n",
       "7   3273056         4833     7802.0   \n",
       "8     94107         3381     7610.0   \n",
       "9    253750         8390     7531.0   \n",
       "10   376492         1041    13490.0   \n",
       "11  1964720         7884     6704.0   \n",
       "12  1113008         1041    11197.0   \n",
       "13  2881376         5341      111.0   \n",
       "14  2881376         8390     7531.0   \n",
       "15  4061024         2709     2840.0   \n",
       "16  4061024         3381     7610.0   \n",
       "17  4061024         7555     9871.0   \n",
       "18  4061024         3381     9776.0   \n",
       "19  7073472         3381     7610.0   \n",
       "\n",
       "    this_month_user_receive_same_coupon_count  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "5                                           1   \n",
       "6                                           1   \n",
       "7                                           1   \n",
       "8                                           1   \n",
       "9                                           1   \n",
       "10                                          1   \n",
       "11                                          1   \n",
       "12                                          1   \n",
       "13                                          2   \n",
       "14                                          1   \n",
       "15                                          1   \n",
       "16                                          1   \n",
       "17                                          1   \n",
       "18                                          1   \n",
       "19                                          1   \n",
       "\n",
       "    this_month_user_receive_all_coupon_count  \\\n",
       "0                                          2   \n",
       "1                                          2   \n",
       "2                                          1   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "5                                          1   \n",
       "6                                          1   \n",
       "7                                          1   \n",
       "8                                          1   \n",
       "9                                          1   \n",
       "10                                         1   \n",
       "11                                         1   \n",
       "12                                         1   \n",
       "13                                         3   \n",
       "14                                         3   \n",
       "15                                         4   \n",
       "16                                         4   \n",
       "17                                         4   \n",
       "18                                         4   \n",
       "19                                         4   \n",
       "\n",
       "    this_month_user_receive_same_coupon_lastone  \\\n",
       "0                                            -1   \n",
       "1                                            -1   \n",
       "2                                            -1   \n",
       "3                                            -1   \n",
       "4                                            -1   \n",
       "5                                            -1   \n",
       "6                                            -1   \n",
       "7                                            -1   \n",
       "8                                            -1   \n",
       "9                                            -1   \n",
       "10                                           -1   \n",
       "11                                           -1   \n",
       "12                                           -1   \n",
       "13                                            1   \n",
       "14                                           -1   \n",
       "15                                           -1   \n",
       "16                                           -1   \n",
       "17                                           -1   \n",
       "18                                           -1   \n",
       "19                                           -1   \n",
       "\n",
       "    this_month_user_receive_same_coupon_firstone  \\\n",
       "0                                             -1   \n",
       "1                                             -1   \n",
       "2                                             -1   \n",
       "3                                             -1   \n",
       "4                                             -1   \n",
       "5                                             -1   \n",
       "6                                             -1   \n",
       "7                                             -1   \n",
       "8                                             -1   \n",
       "9                                             -1   \n",
       "10                                            -1   \n",
       "11                                            -1   \n",
       "12                                            -1   \n",
       "13                                             1   \n",
       "14                                            -1   \n",
       "15                                            -1   \n",
       "16                                            -1   \n",
       "17                                            -1   \n",
       "18                                            -1   \n",
       "19                                            -1   \n",
       "\n",
       "    this_day_user_receive_all_coupon_count  \\\n",
       "0                                        1   \n",
       "1                                        1   \n",
       "2                                        1   \n",
       "3                                        1   \n",
       "4                                        1   \n",
       "5                                        1   \n",
       "6                                        1   \n",
       "7                                        1   \n",
       "8                                        1   \n",
       "9                                        1   \n",
       "10                                       1   \n",
       "11                                       1   \n",
       "12                                       1   \n",
       "13                                       2   \n",
       "14                                       1   \n",
       "15                                       2   \n",
       "16                                       1   \n",
       "17                                       1   \n",
       "18                                       2   \n",
       "19                                       1   \n",
       "\n",
       "    this_day_user_receive_same_coupon_count  day_gap_before  day_gap_after  \\\n",
       "0                                         1              -1             -1   \n",
       "1                                         1              -1             -1   \n",
       "2                                         1              -1             -1   \n",
       "3                                         1              -1             -1   \n",
       "4                                         1              -1             -1   \n",
       "5                                         1              -1             -1   \n",
       "6                                         1              -1             -1   \n",
       "7                                         1              -1             -1   \n",
       "8                                         1              -1             -1   \n",
       "9                                         1              -1             -1   \n",
       "10                                        1              -1             -1   \n",
       "11                                        1              -1             -1   \n",
       "12                                        1              -1             -1   \n",
       "13                                        2              -1             -1   \n",
       "14                                        1              -1             -1   \n",
       "15                                        1              -1             -1   \n",
       "16                                        1              -1             -1   \n",
       "17                                        1              -1             -1   \n",
       "18                                        1              -1             -1   \n",
       "19                                        1              -1             -1   \n",
       "\n",
       "    couponNumInEachMerPerUser  NUniqueMerNumPerUser  \n",
       "0                           2                     1  \n",
       "1                           2                     1  \n",
       "2                           1                     1  \n",
       "3                           1                     1  \n",
       "4                           1                     1  \n",
       "5                           1                     1  \n",
       "6                           1                     1  \n",
       "7                           1                     1  \n",
       "8                           1                     1  \n",
       "9                           1                     1  \n",
       "10                          1                     1  \n",
       "11                          1                     1  \n",
       "12                          1                     1  \n",
       "13                          2                     2  \n",
       "14                          1                     2  \n",
       "15                          1                     3  \n",
       "16                          2                     3  \n",
       "17                          1                     3  \n",
       "18                          2                     3  \n",
       "19                          1                     3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[[\"User_id\", \"Merchant_id\", \"Coupon_id\",\n",
    "       'this_month_user_receive_same_coupon_count',\n",
    "       'this_month_user_receive_all_coupon_count',\n",
    "       'this_month_user_receive_same_coupon_lastone',\n",
    "       'this_month_user_receive_same_coupon_firstone',\n",
    "       'this_day_user_receive_all_coupon_count',\n",
    "       'this_day_user_receive_same_coupon_count', 'day_gap_before',\n",
    "       'day_gap_after',\n",
    "       \"couponNumInEachMerPerUser\", \"NUniqueMerNumPerUser\"]].iloc[0:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', \n",
    "       'Distance', \n",
    "       'weekday', 'weekday_type', \n",
    "       'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7',\n",
    "       'merchantNumPerUser',\n",
    "       'distPerUser',\n",
    "       'couponNumPerUser',\n",
    "       'goodDiscountCouNumPerUser',\n",
    "       'goodDiscountrateAvgDistPerUser'] + ['this_month_user_receive_same_coupon_count',\n",
    "       'this_month_user_receive_all_coupon_count',\n",
    "       'this_month_user_receive_same_coupon_lastone',\n",
    "       'this_month_user_receive_same_coupon_firstone',\n",
    "       'this_day_user_receive_all_coupon_count',\n",
    "       'this_day_user_receive_same_coupon_count', 'day_gap_before',\n",
    "       'day_gap_after'] + [\"couponNumInEachMerPerUser\", \"NUniqueMerNumPerUser\"] + [\"day_1_couponNumInEachMerPerUser\",\n",
    "       \"day_2_couponNumInEachMerPerUser\", \"day_3_couponNumInEachMerPerUser\", \"day_4_couponNumInEachMerPerUser\",\n",
    "       \"day_5_couponNumInEachMerPerUser\", \"day_6_couponNumInEachMerPerUser\", \"day_7_couponNumInEachMerPerUser\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', \n",
    "#        'Distance', \n",
    "#        'weekday_type', \n",
    "#        'merchantNumPerUser',\n",
    "#        'distPerUser',\n",
    "#        'couponNumPerUser',\n",
    "#        'goodDiscountCouNumPerUser',\n",
    "#        'goodDiscountrateAvgDistPerUser'] + ['this_month_user_receive_same_coupon_count',\n",
    "#        'this_month_user_receive_all_coupon_count',\n",
    "#        'this_month_user_receive_same_coupon_lastone',\n",
    "#        'this_month_user_receive_same_coupon_firstone',\n",
    "#        'this_day_user_receive_all_coupon_count',\n",
    "#        'this_day_user_receive_same_coupon_count', 'day_gap_before',\n",
    "#        'day_gap_after'] + [\"couponNumInEachMerPerUser\", \"NUniqueMerNumPerUser\"] + [\"day_1_couponNumInEachMerPerUser\",\n",
    "#        \"day_2_couponNumInEachMerPerUser\", \"day_3_couponNumInEachMerPerUser\", \"day_4_couponNumInEachMerPerUser\",\n",
    "#        \"day_5_couponNumInEachMerPerUser\", \"day_6_couponNumInEachMerPerUser\", \"day_7_couponNumInEachMerPerUser\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>Distance</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_type</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>...</th>\n",
       "      <th>day_gap_after</th>\n",
       "      <th>couponNumInEachMerPerUser</th>\n",
       "      <th>NUniqueMerNumPerUser</th>\n",
       "      <th>day_1_couponNumInEachMerPerUser</th>\n",
       "      <th>day_2_couponNumInEachMerPerUser</th>\n",
       "      <th>day_3_couponNumInEachMerPerUser</th>\n",
       "      <th>day_4_couponNumInEachMerPerUser</th>\n",
       "      <th>day_5_couponNumInEachMerPerUser</th>\n",
       "      <th>day_6_couponNumInEachMerPerUser</th>\n",
       "      <th>day_7_couponNumInEachMerPerUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  discount_type  discount_man  discount_jian  Distance  \\\n",
       "0           0.95              1            20              1       0.0   \n",
       "1           0.95              1            20              1       0.0   \n",
       "2           0.90              1           200             20       0.0   \n",
       "3           0.90              1           200             20       1.0   \n",
       "4           0.50              1            10              5       2.0   \n",
       "\n",
       "   weekday  weekday_type  weekday_1  weekday_2  weekday_3  \\\n",
       "0      3.0             0          0          0          1   \n",
       "1      6.0             0          0          0          0   \n",
       "2      5.0             0          0          0          0   \n",
       "3      5.0             0          0          0          0   \n",
       "4      5.0             0          0          0          0   \n",
       "\n",
       "                ...                 day_gap_after  couponNumInEachMerPerUser  \\\n",
       "0               ...                            -1                          2   \n",
       "1               ...                            -1                          2   \n",
       "2               ...                            -1                          1   \n",
       "3               ...                            -1                          1   \n",
       "4               ...                            -1                          1   \n",
       "\n",
       "   NUniqueMerNumPerUser  day_1_couponNumInEachMerPerUser  \\\n",
       "0                     1                                0   \n",
       "1                     1                                0   \n",
       "2                     1                                0   \n",
       "3                     1                                0   \n",
       "4                     1                                0   \n",
       "\n",
       "   day_2_couponNumInEachMerPerUser  day_3_couponNumInEachMerPerUser  \\\n",
       "0                                0                                1   \n",
       "1                                0                                1   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   day_4_couponNumInEachMerPerUser  day_5_couponNumInEachMerPerUser  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                1   \n",
       "3                                0                                1   \n",
       "4                                0                                1   \n",
       "\n",
       "   day_6_couponNumInEachMerPerUser  day_7_couponNumInEachMerPerUser  \n",
       "0                                1                                0  \n",
       "1                                1                                0  \n",
       "2                                0                                0  \n",
       "3                                0                                0  \n",
       "4                                0                                0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " << na_check(train2[col]) >>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " << na_check(test2[col]) >>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n << na_check(train2[col]) >>\")\n",
    "display(na_check(train2[col]))\n",
    "\n",
    "print(\"\\n << na_check(test2[col]) >>\")\n",
    "display(na_check(test2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "X = train2[col]\n",
    "y = np.ravel(train2[\"label\"])\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# X = mms.fit_transform(train2[col])\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "\n",
    "# 哭喔 剛剛train-test-split 的 X_test撞名稱了啦 下面這個才是我要的\n",
    "# test2 = mms.fit_transform(test2[col])\n",
    "test2 = test2[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用第二版的資料整理而已\n",
    "#----------------------------------------------------------- max_features 也改成 10\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=10, # 最多要看col有幾個feature\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True,\n",
    "                            random_state = 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304096"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(os.path.join(data_path, 'midTerm_1.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 線性迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict_proba(test2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(X_train, y_train)\n",
    "gdbt_pred = gdbt.predict_proba(test2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict_proba(test2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入 xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "xgb = XGBClassifier(max_depth=3, n_estimators=300, \n",
    "                    learning_rate=0.05, random_state = 87)\n",
    "# xgboost 預測檔\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict_proba(test2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.12 + rf_pred * 0.8 + xgb_pred * 0.08\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# # submit.to_csv(os.path.join(data_path, 'midTerm_22.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.2 + rf_pred * 0.7 + xgb_pred * 0.1\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# # submit.to_csv(os.path.join(data_path, 'midTerm_23.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.2 + rf_pred * 0.6 + xgb_pred * 0.2\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_24.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.2 + rf_pred * 0.1 + xgb_pred * 0.7\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_25.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.15 + rf_pred * 0.8 + xgb_pred * 0.05\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# # submit.to_csv(os.path.join(data_path, 'midTerm_26.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "def createUid(row):\n",
    "    return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "predict = lr_pred * 0.3 + rf_pred * 0.6 + xgb_pred * 0.1\n",
    "submit['label'] = predict\n",
    "\n",
    "submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_27.csv'), index=False)\n",
    "\n",
    "\n",
    "# Public Score : 0.77765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.4 + rf_pred * 0.5 + xgb_pred * 0.1\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# # submit.to_csv(os.path.join(data_path, 'midTerm_28.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "def createUid(row):\n",
    "    return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "predict = lr_pred * 0.25 + rf_pred * 0.7 + xgb_pred * 0.05\n",
    "submit['label'] = predict\n",
    "\n",
    "submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "submit.to_csv(os.path.join(data_path, 'midTerm_29.csv'), index=False)\n",
    "\n",
    "\n",
    "# Public Score : 0.77745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = lr_pred * 0.7 + rf_pred * 0.2 + xgb_pred * 0.1\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_30.csv'), index=False)\n",
    "\n",
    "\n",
    "# # score : 0.77369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# meta_estimator = GradientBoostingClassifier(tol=100, subsample=0.70, n_estimators=100, \n",
    "#                                            max_features='sqrt', max_depth=4, learning_rate=0.3)\n",
    "# \"\"\"\n",
    "# Your Code Here\n",
    "# \"\"\"\n",
    "# stacking = StackingClassifier(classifiers=[lr, rf, xgb], meta_classifier = meta_estimator)\n",
    "\n",
    "\n",
    "# stacking.fit(X_train, y_train)\n",
    "# stacking_pred = stacking.predict(test2)\n",
    "\n",
    "\n",
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = stacking_pred\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# # submit.to_csv(os.path.join(data_path, 'midTerm_31.csv'), index=False)\n",
    "\n",
    "\n",
    "# # Public Score : 0.53208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# meta_estimator = RandomForestClassifier(n_estimators=200, min_samples_split=2, min_samples_leaf=2, \n",
    "#                             max_features='sqrt', max_depth=5, bootstrap=True,\n",
    "#                             random_state = 87)\n",
    "# \"\"\"\n",
    "# Your Code Here\n",
    "# \"\"\"\n",
    "# stacking = StackingClassifier(classifiers=[lr, rf, xgb], meta_classifier = meta_estimator)\n",
    "\n",
    "\n",
    "# stacking.fit(X_train, y_train)\n",
    "# stacking_pred = stacking.predict(test2)\n",
    "\n",
    "\n",
    "# # submit\n",
    "# def createUid(row):\n",
    "#     return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "# submit = pd.DataFrame()\n",
    "# submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "# predict = stacking_pred\n",
    "# submit['label'] = predict\n",
    "\n",
    "# submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_32.csv'), index=False)\n",
    "\n",
    "\n",
    "# # Public Score : 0.53202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入新特徵後回到Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "def createUid(row):\n",
    "    return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "predict = lr_pred * 0.3 + rf_pred * 0.6 + xgb_pred * 0.1\n",
    "submit['label'] = predict\n",
    "\n",
    "submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_33.csv'), index=False)\n",
    "\n",
    "\n",
    "# Public Score : 0.77668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "def createUid(row):\n",
    "    return str(row['User_id']) + '_' + str(int(row['Coupon_id'])) + '_' + str(int(row['Date_received']))\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['uid'] = test2_cp.apply(createUid, axis=1)\n",
    "predict = lr_pred * 0.3 + rf_pred * 0.6 + xgb_pred * 0.1\n",
    "submit['label'] = predict\n",
    "\n",
    "submit = submit.groupby(\"uid\", as_index=False).mean()\n",
    "\n",
    "# submit.to_csv(os.path.join(data_path, 'midTerm_34.csv'), index=False)\n",
    "\n",
    "\n",
    "# Public Score : 0.77664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ben19770209 厲害的人\n",
    "\n",
    "https://nbviewer.jupyter.org/github/tobby168/100Day-ML-Marathon/blob/master/Midterm.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/lianglirong/alibaba-tianchi-o2o kaggle kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://tianchi.aliyun.com/competition/entrance/231593/introduction 官方網站\n",
    "\n",
    "https://redstonewill.com/1681/ 紅色石頭: 介紹與範例\n",
    "\n",
    "https://github.com/RedstoneWill/MachineLearningInAction-Camp/blob/master/Week1/o2o-1.ipynb (0.532344469452)\n",
    "\n",
    "https://github.com/RedstoneWill/MachineLearningInAction-Camp/blob/master/Week5/Assignments/o2o-1.ipynb (0.532344469452)\n",
    "\n",
    "https://github.com/RedstoneWill/MachineLearningInAction-Camp/blob/master/Week10/Assignments/o2o-2.ipynb (0.630400363653)\n",
    "\n",
    "https://github.com/wepe/O2O-Coupon-Usage-Forecast 第一名隊伍的註解\n",
    "\n",
    "https://www.kaggle.com/lianglirong/alibaba-tianchi-o2o (0.9094526220772331) 範例\n",
    "\n",
    "https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.15.29281b48IrTtER&postId=8462 (0.909452622077) 100行代码入门天池O2O优惠券使用新人赛【精简教程版】\n",
    "\n",
    "https://www.kaggle.com/cbrogan/xgboost-example-python XGBoost example (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/wepe/O2O-Coupon-Usage-Forecast\n",
    "\n",
    "https://github.com/wepe/O2O-Coupon-Usage-Forecast/blob/master/code/wepon/season%20one/extract_feature.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extractFeature(dataset3):\n",
    "    # this_month_user_receive_all_coupon_count\n",
    "    t = dataset3[['User_id']]\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    print(\"\\n t : this_month_user_receive_all_coupon_count\")\n",
    "    display(t.head())\n",
    "\n",
    "    # this_month_user_receive_same_coupon_count\n",
    "    t1 = dataset3[['User_id','Coupon_id']]\n",
    "    t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "    t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "    print(\"\\n t1 : this_month_user_receive_same_coupon_count\")\n",
    "    display(t1.head())\n",
    "\n",
    "    \n",
    "    t2 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t2.Date_received = t2.Date_received.astype('str')\n",
    "    t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    t2['receive_number'] = t2.Date_received.apply(lambda s:len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number>1]\n",
    "    t2['max_Date_received'] = t2.Date_received.apply(lambda s:max([float(d) for d in s.split(':')]))\n",
    "    t2['min_Date_received'] = t2.Date_received.apply(lambda s:min([float(d) for d in s.split(':')]))\n",
    "    t2 = t2[['User_id','Coupon_id','max_Date_received','min_Date_received']]\n",
    "    print(\"\\n t2 : max_Date_received, min_Date_received\")\n",
    "    display(t2.head())\n",
    "\n",
    "    # this_month_user_receive_same_coupon_lastone, this_month_user_receive_same_coupon_firstone\n",
    "    t3 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t3 = pd.merge(t3,t2,on=['User_id','Coupon_id'],how='left')\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] = t3.max_Date_received - t3.Date_received\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.Date_received - t3.min_Date_received\n",
    "    print(\"\\n t3 : this_month_user_receive_same_coupon_lastone, this_month_user_receive_same_coupon_firstone\")\n",
    "    display(t3.head())\n",
    "    \n",
    "    def is_firstlastone(x):\n",
    "        if x==0:\n",
    "            return 1\n",
    "        elif x>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1 #those only receive once\n",
    "\n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "    t3 = t3[['User_id','Coupon_id','Date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "    print(\"\\n t3 : this_month_user_receive_same_coupon_lastone, this_month_user_receive_same_coupon_firstone\")\n",
    "    display(t3.head())\n",
    "    \n",
    "    # this_day_user_receive_all_coupon_count\n",
    "    t4 = dataset3[['User_id','Date_received']]\n",
    "    t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "    print(\"\\n t4 : this_day_user_receive_all_coupon_count\")\n",
    "    display(t4.head())\n",
    "    \n",
    "    # Date_received\n",
    "    t5 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "    print(\"\\n t5 : Date_received\")\n",
    "    display(t5.head())\n",
    "    \n",
    "    t6 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t6.Date_received = t6.Date_received.astype('str')\n",
    "    t6 = t6.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    t6.rename(columns={'Date_received':'dates'},inplace=True)\n",
    "    print(\"\\n t6 : rename(columns={'Date_received':'dates'},inplace=True)\")\n",
    "    display(t6.head())\n",
    "    \n",
    "    def get_day_gap_before(s):\n",
    "        if str(s)==\"nan\":\n",
    "            return -1\n",
    "        Date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "    def get_day_gap_after(s):\n",
    "        if str(s)==\"nan\":\n",
    "            return -1\n",
    "        Date_received,dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))).days\n",
    "            if this_gap>0:\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "\n",
    "    t7 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "    t7 = pd.merge(t7,t6,on=['User_id','Coupon_id'],how='left')\n",
    "    t7['Date_received_date'] = t7.Date_received.astype('str') + '-' + t7.dates\n",
    "    t7['day_gap_before'] = t7.Date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.Date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[['User_id','Coupon_id','Date_received','day_gap_before','day_gap_after']]\n",
    "    print(\"\\n t7 : day_gap_before, day_gap_after\")\n",
    "    display(t7.head())\n",
    "    \n",
    "    other_feature3 = pd.merge(t1,t,on='User_id')\n",
    "    other_feature3 = pd.merge(other_feature3,t3,on=['User_id','Coupon_id'])\n",
    "    other_feature3 = pd.merge(other_feature3,t4,on=['User_id','Date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3,t5,on=['User_id','Coupon_id','Date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3,t7,on=['User_id','Coupon_id','Date_received'])\n",
    "    #other_feature3.to_csv('data/other_feature3.csv',index=None)\n",
    "    \n",
    "    return other_feature3\n",
    "\n",
    "\n",
    "extractFeature(train).iloc[0:50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
